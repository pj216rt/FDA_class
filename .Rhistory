z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda,
"\n df=", sprintf("%.2f", df_eff)),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n - df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
print(diag(S))
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n - df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
print(n)
sigma2_hat <- sum((y - yhat)^2) / (n - df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n - df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
lambda_grid <- c(0, 0.5, 1, 5, 50, 100)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n - df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
#basis (B-splines) and design matrix
K <- 10
library(tidyverse)
library(R.matlab)
library(splines)
library(glmnet)
library(GGally)
library(patchwork)
library(splines2)
#basis (B-splines) and design matrix
K <- 10
B  <- bs(t, df = K, intercept = TRUE)
dt <- diff(t)[1]
#for trapezoid rule
wt_obs <- c(dt/2, rep(dt, length(t)-2), dt/2)
#trying to keep the same notation as Silverman
Phi <- Fmat %*% (B*wt_obs)
#weight matrix
W <- diag(nrow(Phi))
#precompute
PhiT_W <- t(Phi) %*% W
PhiT_W_Phi <- PhiT_W %*% Phi
t_dense <- seq(min(t), max(t), length.out = 200)
B_dense <- bs(t_dense, df = K, intercept = TRUE)
L <- B_dense
#second difference penalty matrix
D2 <- diff(diag(K), differences = 2)
P  <- crossprod(D2)
#function to build continuous penalty
q6.pen <- function(K, t, M){
t_pen <- seq(t[1], t[2], length.out = M)
#getting the stepsize
h <- (t_pen[2] - t_pen[1])
#weights
w <- c(h/2, rep(h, M-2), h/2)
#get B splines and second derivatives of B splines
B2 <- bSpline(t_pen, df = K, intercept = TRUE, derivs = 2)
#initialize penalty matrix
P <- matrix(0, nrow = K, ncol = K)
#loop
for (i in 1:K) {
for (j in i:K) {
val <- sum(w * B2[, i] * B2[, j])
P[i, j] <- val
P[j, i] <- val
}
}
return(P)
}
test <- q6.pen(K=5, t = t, M = 500)
lambda_grid <- c(0, 0.5, 1, 5, 50, 100)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n-df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
K <- 30
B  <- bs(t, df = K, intercept = TRUE)
dt <- diff(t)[1]
#for trapezoid rule
wt_obs <- c(dt/2, rep(dt, length(t)-2), dt/2)
# X  <- Fmat %*% (B*dt)
#trying to keep the same notation as Silverman
Phi <- Fmat %*% (B*wt_obs)
#weight matrix
W <- diag(nrow(Phi))
#precompute
PhiT_W <- t(Phi) %*% W
PhiT_W_Phi <- PhiT_W %*% Phi
t_dense <- seq(min(t), max(t), length.out = 200)
B_dense <- bs(t_dense, df = K, intercept = TRUE)
L <- B_dense
#second difference penalty matrix
D2 <- diff(diag(K), differences = 2)
P  <- crossprod(D2)
#function to build continuous penalty
q6.pen <- function(K, t, M){
t_pen <- seq(t[1], t[2], length.out = M)
#getting the stepsize
h <- (t_pen[2] - t_pen[1])
#weights
w <- c(h/2, rep(h, M-2), h/2)
#get B splines and second derivatives of B splines
B2 <- bSpline(t_pen, df = K, intercept = TRUE, derivs = 2)
#initialize penalty matrix
P <- matrix(0, nrow = K, ncol = K)
#loop
for (i in 1:K) {
for (j in i:K) {
val <- sum(w * B2[, i] * B2[, j])
P[i, j] <- val
P[j, i] <- val
}
}
return(P)
}
test <- q6.pen(K=5, t = t, M = 500)
#two different penalty matrices.  One based on second differences.  The other based
#on approximating the integral
# P
# test
lambda_grid <- c(0, 0.5, 1, 5, 50, 100)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n-df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
#basis (B-splines) and design matrix
K <- 20
B  <- bs(t, df = K, intercept = TRUE)
dt <- diff(t)[1]
#for trapezoid rule
wt_obs <- c(dt/2, rep(dt, length(t)-2), dt/2)
#trying to keep the same notation as Silverman
Phi <- Fmat %*% (B*wt_obs)
#weight matrix
W <- diag(nrow(Phi))
#precompute
PhiT_W <- t(Phi) %*% W
PhiT_W_Phi <- PhiT_W %*% Phi
t_dense <- seq(min(t), max(t), length.out = 200)
B_dense <- bs(t_dense, df = K, intercept = TRUE)
L <- B_dense
#second difference penalty matrix
D2 <- diff(diag(K), differences = 2)
P  <- crossprod(D2)
#function to build continuous penalty
q6.pen <- function(K, t, M){
t_pen <- seq(t[1], t[2], length.out = M)
#getting the stepsize
h <- (t_pen[2] - t_pen[1])
#weights
w <- c(h/2, rep(h, M-2), h/2)
#get B splines and second derivatives of B splines
B2 <- bSpline(t_pen, df = K, intercept = TRUE, derivs = 2)
#initialize penalty matrix
P <- matrix(0, nrow = K, ncol = K)
#loop
for (i in 1:K) {
for (j in i:K) {
val <- sum(w * B2[, i] * B2[, j])
P[i, j] <- val
P[j, i] <- val
}
}
return(P)
}
test <- q6.pen(K=5, t = t, M = 500)
lambda_grid <- c(0, 0.5, 1, 5, 50, 100)
#function to fit and return CIs for one lambda
fit_one_lambda <- function(lambda) {
A <- A <- PhiT_W_Phi + (lambda*P)
S <- solve(A, PhiT_W)
#coefficients and predicted values
chat <- as.vector(S %*% y)
yhat <- as.vector(Phi %*% chat)
#degrees of freedom
Hdiag  <- rowSums(Phi * t(S))
df_eff <- sum(Hdiag)
#estimate of sigma^2
n <- nrow(Phi)
sigma2_hat <- sum((y - yhat)^2) / (n-df_eff)
#computing variance and CIS
LS <- L %*% S
beta_var <- sigma2_hat * rowSums(LS*LS)
beta_hat <- as.vector(L %*% chat)
beta_se  <- sqrt(beta_var)
#critical Z value for 95% CI
z <- qnorm(0.975)
#create dataframe for outputs
data.frame(
t        = t_dense,
beta     = beta_hat,
lo       = beta_hat - (z*beta_se),
hi       = beta_hat + (z*beta_se),
lambda   = lambda,
lambda_lab = paste0("Lambda=", lambda),
df_eff   = df_eff
)
}
df_all <- do.call(rbind, lapply(lambda_grid, fit_one_lambda))
#plot this
ggplot(df_all, aes(x = t, y = beta)) +
geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.18) +
geom_line(linewidth = 1) +
facet_wrap(~ lambda_lab, ncol = 3) +
labs(
title = expression(hat(beta)(t) ~ "with 95% pointwise CI for Penalized/Unpenalized regression"),
subtitle = "95% Confidence Intervals Shown",
x = "t",
y = expression(hat(beta)(t))
) +
theme_minimal(base_size = 14)
problem2 <- function(p, q, n_steps = 1000){
#for unit vectors a,b in Hilbert space, \theta = arccos({x,y})
angle <- acos(sum(p * q))
#create matrix to hold the path
}
problem2 <- function(p, q, n_steps = 1000){
#for unit vectors a,b in Hilbert space, \theta = arccos({x,y})
angle <- acos(sum(p * q))
#create matrix to hold the path
#each row will be the path at t = n_step_i, and the length will
#correspond to the length of the vector
path <- matrix(NA, nrow = n_steps, ncol = length(p))
#computing path
for (i in 1:n_steps) {
}
}
